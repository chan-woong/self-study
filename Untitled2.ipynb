{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOnmxLjCjTwwDyHG7fmAsc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chan-woong/self-study/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLsKzZ5cnqD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7b634a6-9612-4cb2-ebb3-784dc7fa51d1"
      },
      "source": [
        "# one-hot encoding 알아보기\n",
        "# tf.one_hot\n",
        "# 아래 모델을 손봐서 val_loss 0.20 이하로 내리기\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "(x_train, y_train), (x_valid, y_valid) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255\n",
        "#print(tf.shape(x_train)) # 28x28x3 이미지 x 60000개\n",
        "#print(tf.shape(y_train))\n",
        "x_train = tf.reshape(x_train, (-1 ,28,28,1))\n",
        "x_valid = tf.reshape(x_valid, (-1, 28,28,1))\n",
        "#Conv2D = 합성곱 \n",
        "#MaxPooling2D = 이미지 축소\n",
        "model = Sequential([\n",
        "      Conv2D(64, (3,3),input_shape = (28,28, 1), activation = 'relu'),\n",
        "      Conv2D(128, (3,3), activation = 'relu'),\n",
        "      MaxPooling2D(2,2),\n",
        "      Conv2D(128, (3,3), activation = 'relu'),\n",
        "      Conv2D(64, (3,3), activation = 'relu'),\n",
        "      Conv2D(32, (3,3), activation = 'relu'),\n",
        "      MaxPooling2D(2,2),\n",
        "      Conv2D(16, (3,3), activation = 'relu'),\n",
        "      Flatten(),\n",
        "      Dense(10, activation = 'softmax'), # sigmoid = Classifier 할때 이진분류에서만 쓰기\n",
        "])\n",
        "model.summary()\n",
        "#softmax일 때 one hot 썼으면 categorical_crossentropy\n",
        "#sigmoid activation 일 경우 binary_crossentropy\n",
        "\n",
        "ckpt_path = \"best.ckpt\"\n",
        "ckpt = ModelCheckpoint(\n",
        "    filepath = ckpt_path,\n",
        "    verbose = 1,\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True\n",
        ")\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
        "model.fit(x_train, y_train, validation_data=(x_valid,y_valid), epochs = 20, callbacks = [ckpt])\n",
        "model.load_weights(ckpt_path)\n",
        "\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_227 (Conv2D)          (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_228 (Conv2D)          (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_100 (MaxPoolin (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_229 (Conv2D)          (None, 10, 10, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_230 (Conv2D)          (None, 8, 8, 64)          73792     \n",
            "_________________________________________________________________\n",
            "conv2d_231 (Conv2D)          (None, 6, 6, 32)          18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_101 (MaxPoolin (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_232 (Conv2D)          (None, 1, 1, 16)          4624      \n",
            "_________________________________________________________________\n",
            "flatten_48 (Flatten)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 319,130\n",
            "Trainable params: 319,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.5355 - acc: 0.8074\n",
            "Epoch 00001: val_loss improved from inf to 0.36768, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5344 - acc: 0.8077 - val_loss: 0.3677 - val_acc: 0.8706\n",
            "Epoch 2/20\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.3244 - acc: 0.8839\n",
            "Epoch 00002: val_loss improved from 0.36768 to 0.32048, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3241 - acc: 0.8840 - val_loss: 0.3205 - val_acc: 0.8867\n",
            "Epoch 3/20\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9002\n",
            "Epoch 00003: val_loss improved from 0.32048 to 0.28421, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2756 - acc: 0.9003 - val_loss: 0.2842 - val_acc: 0.8965\n",
            "Epoch 4/20\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2455 - acc: 0.9107\n",
            "Epoch 00004: val_loss did not improve from 0.28421\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2455 - acc: 0.9107 - val_loss: 0.2876 - val_acc: 0.8997\n",
            "Epoch 5/20\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9187\n",
            "Epoch 00005: val_loss improved from 0.28421 to 0.28005, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2239 - acc: 0.9186 - val_loss: 0.2800 - val_acc: 0.9015\n",
            "Epoch 6/20\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9263\n",
            "Epoch 00006: val_loss improved from 0.28005 to 0.24655, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2019 - acc: 0.9263 - val_loss: 0.2465 - val_acc: 0.9136\n",
            "Epoch 7/20\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9323\n",
            "Epoch 00007: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1869 - acc: 0.9322 - val_loss: 0.2669 - val_acc: 0.9053\n",
            "Epoch 8/20\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9380\n",
            "Epoch 00008: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1688 - acc: 0.9379 - val_loss: 0.2590 - val_acc: 0.9121\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1535 - acc: 0.9436\n",
            "Epoch 00009: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1535 - acc: 0.9436 - val_loss: 0.2668 - val_acc: 0.9115\n",
            "Epoch 10/20\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9490\n",
            "Epoch 00010: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1407 - acc: 0.9490 - val_loss: 0.2670 - val_acc: 0.9186\n",
            "Epoch 11/20\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9534\n",
            "Epoch 00011: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1272 - acc: 0.9535 - val_loss: 0.2792 - val_acc: 0.9138\n",
            "Epoch 12/20\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9578\n",
            "Epoch 00012: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1147 - acc: 0.9578 - val_loss: 0.2845 - val_acc: 0.9107\n",
            "Epoch 13/20\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9614\n",
            "Epoch 00013: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1051 - acc: 0.9615 - val_loss: 0.3071 - val_acc: 0.9118\n",
            "Epoch 14/20\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9649\n",
            "Epoch 00014: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0963 - acc: 0.9649 - val_loss: 0.3010 - val_acc: 0.9118\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0881 - acc: 0.9673\n",
            "Epoch 00015: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0881 - acc: 0.9673 - val_loss: 0.3221 - val_acc: 0.9140\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0822 - acc: 0.9705\n",
            "Epoch 00016: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0822 - acc: 0.9705 - val_loss: 0.3513 - val_acc: 0.9096\n",
            "Epoch 17/20\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9732\n",
            "Epoch 00017: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0748 - acc: 0.9732 - val_loss: 0.3439 - val_acc: 0.9103\n",
            "Epoch 18/20\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9743\n",
            "Epoch 00018: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0715 - acc: 0.9743 - val_loss: 0.3864 - val_acc: 0.9072\n",
            "Epoch 19/20\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9751\n",
            "Epoch 00019: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0687 - acc: 0.9751 - val_loss: 0.4082 - val_acc: 0.9048\n",
            "Epoch 20/20\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9774\n",
            "Epoch 00020: val_loss did not improve from 0.24655\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0614 - acc: 0.9774 - val_loss: 0.4111 - val_acc: 0.9082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff7c623a8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}