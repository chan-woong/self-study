{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpcVxBPXl1JrryELDw0sQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chan-woong/self-study/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLsKzZ5cnqD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1fd3f8e-e694-4115-92e2-0f1119067e89"
      },
      "source": [
        "# one-hot encoding 알아보기\n",
        "# tf.one_hot\n",
        "# 아래 모델을 손봐서 val_loss 0.20 이하로 내리기\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "(x_train, y_train), (x_valid, y_valid) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255\n",
        "#print(tf.shape(x_train)) # 28x28x3 이미지 x 60000개\n",
        "#print(tf.shape(y_train))\n",
        "x_train = tf.reshape(x_train, (-1 ,28,28,1))\n",
        "x_valid = tf.reshape(x_valid, (-1, 28,28,1))\n",
        "#Conv2D = 합성곱 \n",
        "#MaxPooling2D = 이미지 축소\n",
        "model = Sequential([\n",
        "      Conv2D(100, (3,3),input_shape = (28,28, 1), activation = 'relu'),\n",
        "      MaxPooling2D(2,2),\n",
        "      Conv2D(84, (3,3), activation = 'relu'),\n",
        "      MaxPooling2D(2,2),\n",
        "      Conv2D(128, (3,3), activation = 'relu'),\n",
        "      Conv2D(63, (3,3), activation = 'relu'),\n",
        "      Flatten(),\n",
        "      Dense(10, activation = 'softmax'), # sigmoid = Classifier 할때 이진분류에서만 쓰기\n",
        "])\n",
        "model.summary()\n",
        "#softmax일 때 one hot 썼으면 categorical_crossentropy\n",
        "#sigmoid activation 일 경우 binary_crossentropy\n",
        "\n",
        "ckpt_path = \"best.ckpt\"\n",
        "ckpt = ModelCheckpoint(\n",
        "    filepath = ckpt_path,\n",
        "    verbose = 1,\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True\n",
        ")\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
        "model.fit(x_train, y_train, validation_data=(x_valid,y_valid), epochs = 20, callbacks = [ckpt])\n",
        "model.load_weights(ckpt_path)\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_38 (Conv2D)           (None, 26, 26, 100)       1000      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 13, 13, 100)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 11, 11, 84)        75684     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 5, 5, 84)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 3, 3, 128)         96896     \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 1, 1, 63)          72639     \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 63)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                640       \n",
            "=================================================================\n",
            "Total params: 246,859\n",
            "Trainable params: 246,859\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8324\n",
            "Epoch 00001: val_loss improved from inf to 0.34059, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4553 - acc: 0.8324 - val_loss: 0.3406 - val_acc: 0.8761\n",
            "Epoch 2/20\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.2986 - acc: 0.8904\n",
            "Epoch 00002: val_loss improved from 0.34059 to 0.28898, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2985 - acc: 0.8905 - val_loss: 0.2890 - val_acc: 0.8949\n",
            "Epoch 3/20\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.2534 - acc: 0.9077\n",
            "Epoch 00003: val_loss improved from 0.28898 to 0.27151, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2532 - acc: 0.9078 - val_loss: 0.2715 - val_acc: 0.9027\n",
            "Epoch 4/20\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.2211 - acc: 0.9180\n",
            "Epoch 00004: val_loss improved from 0.27151 to 0.27094, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2210 - acc: 0.9179 - val_loss: 0.2709 - val_acc: 0.9013\n",
            "Epoch 5/20\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9266\n",
            "Epoch 00005: val_loss improved from 0.27094 to 0.25210, saving model to best.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1967 - acc: 0.9266 - val_loss: 0.2521 - val_acc: 0.9093\n",
            "Epoch 6/20\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9350\n",
            "Epoch 00006: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1746 - acc: 0.9350 - val_loss: 0.2619 - val_acc: 0.9032\n",
            "Epoch 7/20\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9412\n",
            "Epoch 00007: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1553 - acc: 0.9413 - val_loss: 0.2649 - val_acc: 0.9077\n",
            "Epoch 8/20\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9482\n",
            "Epoch 00008: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1377 - acc: 0.9482 - val_loss: 0.2874 - val_acc: 0.9068\n",
            "Epoch 9/20\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9544\n",
            "Epoch 00009: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1217 - acc: 0.9544 - val_loss: 0.2676 - val_acc: 0.9100\n",
            "Epoch 10/20\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9579\n",
            "Epoch 00010: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1092 - acc: 0.9579 - val_loss: 0.2971 - val_acc: 0.9098\n",
            "Epoch 11/20\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9636\n",
            "Epoch 00011: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0965 - acc: 0.9636 - val_loss: 0.3145 - val_acc: 0.9098\n",
            "Epoch 12/20\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9660\n",
            "Epoch 00012: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0899 - acc: 0.9661 - val_loss: 0.3277 - val_acc: 0.9121\n",
            "Epoch 13/20\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9700\n",
            "Epoch 00013: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0794 - acc: 0.9700 - val_loss: 0.3268 - val_acc: 0.9049\n",
            "Epoch 14/20\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9722\n",
            "Epoch 00014: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0728 - acc: 0.9722 - val_loss: 0.3891 - val_acc: 0.9099\n",
            "Epoch 15/20\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9749\n",
            "Epoch 00015: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0661 - acc: 0.9749 - val_loss: 0.4032 - val_acc: 0.9130\n",
            "Epoch 16/20\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9772\n",
            "Epoch 00016: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0623 - acc: 0.9771 - val_loss: 0.4287 - val_acc: 0.9078\n",
            "Epoch 17/20\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9770\n",
            "Epoch 00017: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0598 - acc: 0.9770 - val_loss: 0.4467 - val_acc: 0.9060\n",
            "Epoch 18/20\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9781\n",
            "Epoch 00018: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0595 - acc: 0.9781 - val_loss: 0.4325 - val_acc: 0.9112\n",
            "Epoch 19/20\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9802\n",
            "Epoch 00019: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0514 - acc: 0.9802 - val_loss: 0.4854 - val_acc: 0.9069\n",
            "Epoch 20/20\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9821\n",
            "Epoch 00020: val_loss did not improve from 0.25210\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0501 - acc: 0.9822 - val_loss: 0.4820 - val_acc: 0.9106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7a200601d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}
